{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Elastic Search Pipeline\n",
    "\n",
    "Create and wire containers:\n",
    "* elasticsearch\n",
    "* kibana\n",
    "* filebeats\n",
    "* logstash\n",
    "\n",
    "All containers are configured to stay up unless stopped. The notebook includes final\n",
    "steps to stop and remove containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace these with the appropriate values for your setup\n",
    "# all components in pipeline should match versions\n",
    "es_version = '6.3.2'\n",
    "# configurations and data for docker containers should be rooted at your\n",
    "# git clone target for this repo https://github.com/louspringer/docker-python-api-elk-provisioning.git\n",
    "# example docker_root=${HOME}/docker-python-api-elk-provisioning\n",
    "docker_root = '/Users/lou/Documents/docker-python-api-elk-provisioning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\r\n",
      "ced9158e6147        influxdb            \"/entrypoint.sh -con…\"   4 weeks ago         Up 31 hours         0.0.0.0:8086->8086/tcp   snow-influxdb\r\n",
      "854c7db780df        mysql:latest        \"docker-entrypoint.s…\"   5 weeks ago         Up 2 days           0.0.0.0:3306->3306/tcp   snow-mysql\r\n"
     ]
    }
   ],
   "source": [
    "# what's curently running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Elasticsearch Container\n",
    "\n",
    "This section replicates the function of this docker cli command\n",
    "```bash\n",
    "docker run -d -p 9200:9200 -p 9300:9300 \\\n",
    "--network=elastic \\\n",
    "--name=elasticsearch \\\n",
    "-v /Users/lou/Documents/elasticsearch/esdata1:/usr/share/elasticsearch/data \\\n",
    "-e \"node.name=alacrity.local\" \\\n",
    "--restart=unless-stopped docker.elastic.co/elasticsearch/elasticsearch:6.3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import socket\n",
    "import uuid\n",
    "client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elasticsearch-b7506b44-977e-4d4e-b13a-e5ecc5f6d71e'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to create a random elastic search container name since we\n",
    "# can't currently directly create an alias. See https://github.com/docker/docker-py/issues/1571\n",
    "es_container_name=\"elasticsearch-{}\".format(str(uuid.uuid4()))\n",
    "es_container_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_image = \"docker.elastic.co/elasticsearch/elasticsearch:{}\".format(es_version)\n",
    "es_container = client.containers.run(\n",
    "    es_image,\n",
    "    name=es_container_name,\n",
    "    detach=True,\n",
    "    network=\"elastic\",\n",
    "    ports={\n",
    "        '9200/tcp': '9200',\n",
    "        '9300/tcp': '9300'\n",
    "    },\n",
    "    volumes={\n",
    "        \"{}/elasticsearch/esdata1\".format(docker_root): {\n",
    "            'bind': '/usr/share/elasticsearch/data',\n",
    "            'mode': 'rw'\n",
    "        }\n",
    "    },\n",
    "    environment={\n",
    "        'node.name': socket.gethostname()\n",
    "    },\n",
    "    restart_policy={\n",
    "        'Name': 'unless-stopped'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Kibana Container\n",
    "This section replicates the function of this docker cli command\n",
    "```bash\n",
    "docker run -d -p 5601:5601 \\\n",
    "--network=elastic \\\n",
    "-e \"ELASTICSEARCH_URL=http://elasticsearch:9200\" \\\n",
    "-v /Users/lou/Documents/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml \\\n",
    "--restart=unless-stopped docker.elastic.co/kibana/kibana:6.3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_image = \"docker.elastic.co/kibana/kibana:{}\".format(es_version)\n",
    "kb_container = client.containers.run(\n",
    "    kb_image,\n",
    "    detach=True,\n",
    "    network=\"elastic\",\n",
    "    environment={\n",
    "        'ELASTICSEARCH_URL': 'http://{}:9200'.format(es_container_name)\n",
    "    },\n",
    "    restart_policy={\n",
    "        'Name': 'unless-stopped'\n",
    "    },\n",
    "    ports={\n",
    "        '5601/tcp': '5601'\n",
    "    },\n",
    "    volumes={\n",
    "        \"{}/kibana/kibana.yml\".format(docker_root): {\n",
    "            'bind': '/usr/share/kibana/config/kibana.yml',\n",
    "            'mode': 'ro'\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Logstash Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_container_name=\"logstash-{}\".format(str(uuid.uuid4()))\n",
    "ls_image = \"docker.elastic.co/logstash/logstash:{}\".format(es_version)\n",
    "ls_container = client.containers.run(\n",
    "    ls_image,\n",
    "    name=ls_container_name,\n",
    "    detach=True,\n",
    "    network='elastic',\n",
    "    restart_policy={\n",
    "        'Name': 'unless-stopped'\n",
    "    },\n",
    "    environment={\n",
    "        'ELASTICSEARCH_HOST': '{}:9200'.format(es_container_name)\n",
    "    },\n",
    "    volumes={\n",
    "        \"{}/logstash/pipeline/\".format(docker_root): {\n",
    "            'bind': '/usr/share/logstash/pipeline/',\n",
    "            'mode': 'rw'\n",
    "        },\n",
    "        \"{}/logstash/config/\".format(docker_root): {\n",
    "            'bind': '/usr/share/logstash/config/',\n",
    "            'mode': 'ro'\n",
    "        },\n",
    "        \"{}/logstash/data\".format(docker_root): {\n",
    "            'bind': '/usr/share/logstash/data',\n",
    "            'mode': 'rw'\n",
    "        }\n",
    "    } \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Filebeat Container\n",
    "\n",
    "The filebeat.yml and the volume specification should be modified to match where filebeat should\n",
    "pick up log files to process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_image = \"docker.elastic.co/beats/filebeat:{}\".format(es_version)\n",
    "fb_container = client.containers.run(\n",
    "    fb_image,\n",
    "    detach=True,\n",
    "    network='elastic',\n",
    "    restart_policy={\n",
    "        'Name': 'unless-stopped'\n",
    "    },\n",
    "    environment={\n",
    "        'LOGSTASH_HOST': '{}:5044'.format(ls_container_name)\n",
    "    },\n",
    "    volumes={\n",
    "        \"{}/filebeat/filebeat.yml\".format(docker_root): {\n",
    "            'bind': '/usr/share/filebeat/filebeat.yml',\n",
    "            'mode': 'ro'\n",
    "        },\n",
    "        \"{}/filebeat/inputlogs\".format(docker_root):{\n",
    "            'bind': '/usr/share/filebeat/inputlogs',\n",
    "            'mode': 'ro'\n",
    "        },\n",
    "        \"{}/filebeat/data\".format(docker_root):{\n",
    "            'bind': '/usr/share/filebeat/data',\n",
    "            'mode': 'rw'\n",
    "        }\n",
    "    }    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                  PORTS                                            NAMES\r\n",
      "feb4a334f093        docker.elastic.co/beats/filebeat:6.3.2                \"/usr/local/bin/dock…\"   1 second ago        Up Less than a second                                                    wizardly_panini\r\n",
      "b6c5edc9a1a3        docker.elastic.co/logstash/logstash:6.3.2             \"/usr/local/bin/dock…\"   2 seconds ago       Up 1 second             5044/tcp, 9600/tcp                               logstash-e79ce71d-4d6c-49e9-88a7-e56be5573ca0\r\n",
      "45dae697c557        docker.elastic.co/kibana/kibana:6.3.2                 \"/usr/local/bin/kiba…\"   3 seconds ago       Up 1 second             0.0.0.0:5601->5601/tcp                           musing_curie\r\n",
      "20958b9626f3        docker.elastic.co/elasticsearch/elasticsearch:6.3.2   \"/usr/local/bin/dock…\"   4 seconds ago       Up 2 seconds            0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   elasticsearch-b7506b44-977e-4d4e-b13a-e5ecc5f6d71e\r\n",
      "ced9158e6147        influxdb                                              \"/entrypoint.sh -con…\"   4 weeks ago         Up 31 hours             0.0.0.0:8086->8086/tcp                           snow-influxdb\r\n",
      "854c7db780df        mysql:latest                                          \"docker-entrypoint.s…\"   5 weeks ago         Up 2 days               0.0.0.0:3306->3306/tcp                           snow-mysql\r\n"
     ]
    }
   ],
   "source": [
    "# what's running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown and Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_container.stop()\n",
    "ls_container.remove()\n",
    "fb_container.stop()\n",
    "fb_container.remove()\n",
    "kb_container.stop()\n",
    "kb_container.remove()\n",
    "es_container.stop()\n",
    "es_container.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\r\n",
      "ced9158e6147        influxdb            \"/entrypoint.sh -con…\"   4 weeks ago         Up 31 hours         0.0.0.0:8086->8086/tcp   snow-influxdb\r\n",
      "854c7db780df        mysql:latest        \"docker-entrypoint.s…\"   5 weeks ago         Up 2 days           0.0.0.0:3306->3306/tcp   snow-mysql\r\n"
     ]
    }
   ],
   "source": [
    "# check what's still running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
